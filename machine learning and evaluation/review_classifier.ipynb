{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# working with data\n",
    "import os\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# text preprocessing libraries \n",
    "import string\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            POS_BAYES  NEG_BAYES\n",
      "Unnamed: 0                      \n",
      "timeless     0.994118   0.005882\n",
      "fallout      0.992701   0.007299\n",
      "selma        0.992424   0.007576\n",
      "superbly     0.991736   0.008264\n",
      "ronan        0.991379   0.008621\n",
      "...               ...        ...\n",
      "roommate     0.007084   0.992916\n",
      "seagal       0.006210   0.993790\n",
      "gotti        0.005737   0.994263\n",
      "flatliners   0.005150   0.994850\n",
      "sara         0.004672   0.995328\n",
      "\n",
      "[40477 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# read in the data\n",
    "path = os.path.join(os.path.normpath(os.getcwd() + os.sep + os.pardir) + \"/data\")\n",
    "\n",
    "#print(os.listdir(path))\n",
    "\n",
    "ml_model = pd.read_csv(path + '/cleaned/ml_model.csv')\n",
    "\n",
    "#print(ml_model.columns[0])\n",
    "ml_model.set_index(ml_model.columns[0], inplace=True)\n",
    "\n",
    "print(ml_model.sort_values(\"NEG_BAYES\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(sample_text):\n",
    "    '''\n",
    "    casefolding, punctuation removal, tokenisation, lemmatisation, stopword removal\n",
    "    '''\n",
    "    sample_text = str(sample_text).lower()\n",
    "    sample_text = sample_text.translate(str.maketrans('','', string.punctuation)) \n",
    "    # Consider using regex to address back to back punctuation, like day-to-day\n",
    "    \n",
    "    sample_text = word_tokenize(sample_text)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    sample_text = [lemmatizer.lemmatize(word) for word in sample_text]\n",
    "\n",
    "    #consider changing this later, to take care of bi grams, where words such as 'not' may be important\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    sample_text = [word for word in sample_text if word not in stop_words]\n",
    "\n",
    "    return sample_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_scorer(ml_model, review, dampener=20):\n",
    "    '''\n",
    "    Generates a score from -100 to 100, based on how strongly positive or negative the ml model predicts a review is\n",
    "    '''\n",
    "    words = clean(review)\n",
    "    pos_score = 1\n",
    "    neg_score = 1\n",
    "    for word in words:\n",
    "        if word in ml_model.index:\n",
    "            certainty = 100* abs(ml_model.at[word, \"POS_BAYES\"] - ml_model.at[word, \"NEG_BAYES\"])\n",
    "            if certainty > dampener:\n",
    "                pos_score *= ml_model.at[word, \"POS_BAYES\"]\n",
    "                neg_score *= ml_model.at[word, \"NEG_BAYES\"]\n",
    "    return 100 * (pos_score - neg_score)/(pos_score + neg_score)\n",
    "\n",
    "def review_classifier(ml_model, review, dampener=20, confidence=30):\n",
    "    '''\n",
    "    Classifies a movie review into one of three categories, based on its score\n",
    "    '''\n",
    "    score = review_scorer(ml_model, review, dampener)\n",
    "    if score >= confidence:\n",
    "        return \"POSITIVE\"\n",
    "    elif score <= -confidence:\n",
    "        return \"NEGATIVE\"\n",
    "    else:\n",
    "        return \"UNSURE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.511276369736056\n",
      "POSITIVE\n",
      "-51.67771361698523\n",
      "NEGATIVE\n",
      "55.59934491457741\n",
      "POSITIVE\n"
     ]
    }
   ],
   "source": [
    "review = \"Watching the film is like bathing in the sun\"\n",
    "print(review_scorer(ml_model, review))\n",
    "print(review_classifier(ml_model, review))\n",
    "\n",
    "review = \"It was like drinking bleach\"\n",
    "print(review_scorer(ml_model, review))\n",
    "print(review_classifier(ml_model, review))\n",
    "\n",
    "review = \"It was like drinking wine\"\n",
    "print(review_scorer(ml_model, review))\n",
    "print(review_classifier(ml_model, review))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-79.41864765945644\n",
      "NEGATIVE\n",
      "99.84215773652208\n",
      "POSITIVE\n"
     ]
    }
   ],
   "source": [
    "review = \"Is there anything hugely wrong with Aquaman? Not really. Is this a missed opportunity? Yes.\"\n",
    "print(review_scorer(ml_model, review))\n",
    "print(review_classifier(ml_model, review))\n",
    "\n",
    "review = \"Aquaman works because it isn't laughing at itself-it's both joyously whimsical and confident in its own sea-worthiness.\"\n",
    "print(review_scorer(ml_model, review))\n",
    "print(review_classifier(ml_model, review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54.40740647547831\n",
      "POSITIVE\n"
     ]
    }
   ],
   "source": [
    "review = \"the movie made me feel sigma and tingly inside\"\n",
    "print(review_scorer(ml_model, review))\n",
    "print(review_classifier(ml_model, review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.712161496686293\n",
      "UNSURE\n"
     ]
    }
   ],
   "source": [
    "review = \"I'd love to never watch this movie again\"\n",
    "print(review_scorer(ml_model, review))\n",
    "print(review_classifier(ml_model, review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation of Ml_model\n",
    "import ast\n",
    "\n",
    "test_data = pd.read_csv(path + '/test/test.csv')\n",
    "\n",
    "def eval_model(ml_model, test_data, confidence):\n",
    "    true_pos = 0\n",
    "    true_neg = 0\n",
    "    false_pos = 0\n",
    "    false_neg = 0\n",
    "    unsure = 0\n",
    "\n",
    "    for review in test_data.itertuples(name='Pandas'):\n",
    "        review_text = review.review_text\n",
    "        sentiment = review.sentiment\n",
    "        prediction = review_classifier(ml_model, review_text, dampener=20, confidence=confidence)\n",
    "        if sentiment == prediction:\n",
    "            if prediction == \"POSITIVE\":\n",
    "                true_pos += 1\n",
    "            elif prediction == \"NEGATIVE\":\n",
    "                true_neg += 1\n",
    "            else:\n",
    "                unsure += 1\n",
    "        else:\n",
    "            if prediction == \"POSITIVE\":\n",
    "                false_pos += 1\n",
    "            elif prediction == \"NEGATIVE\":\n",
    "                false_neg += 1\n",
    "            else:\n",
    "                unsure += 1\n",
    "    return (true_pos, true_neg, false_pos, false_neg, unsure)\n",
    "\n",
    "true_pos, true_neg, false_pos, false_neg, indecision = eval_model(ml_model, test_data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72.02998846597463 76.37603507062835 65.72438162544168\n",
      "73.20261437908496 79.83706720977597 70.13574660633485 61.83510638297872\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "#ml_model evaluation metrics\n",
    "total_decisions = false_pos + false_neg + true_pos + true_neg\n",
    "accuracy = 100 * (true_pos + true_neg) / total_decisions\n",
    "pos_precision = 100 * true_pos / (true_pos + false_pos)\n",
    "pos_recall = 100 * true_pos / (true_pos + false_neg)\n",
    "pos_f1 = 2 * pos_precision * pos_recall / (pos_recall + pos_precision)\n",
    "neg_precision = 100 * true_neg / (true_neg + false_neg)\n",
    "neg_recall = 100 * true_neg / (true_neg + false_pos)\n",
    "neg_f1 = 2 * neg_precision * neg_recall / (neg_recall + neg_precision)\n",
    "reliability = total_decisions / (total_decisions + indecision)\n",
    "\n",
    "print(accuracy, pos_f1, neg_f1)\n",
    "print(pos_precision, pos_recall, neg_precision, neg_recall)\n",
    "print(reliability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "982\n",
      "752\n"
     ]
    }
   ],
   "source": [
    "print(len(test_data.loc[test_data[\"sentiment\"] == \"POSITIVE\"]))\n",
    "print(len(test_data.loc[test_data[\"sentiment\"] == \"NEGATIVE\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 72.02998846597463 76.37603507062835 65.72438162544168 1.0\n",
      "1 72.2189866045428 76.46768623581647 66.09808102345416 0.9901960784313726\n",
      "2 72.34915055653192 76.58730158730158 66.23748211731044 0.9844290657439446\n",
      "3 72.44418331374852 76.67826951765291 66.33165829145729 0.9815455594002307\n",
      "4 72.59870359457867 76.80798004987531 66.52267818574514 0.9786620530565168\n",
      "5 72.91049199762892 77.09273182957394 66.8600435097897 0.9728950403690888\n",
      "6 72.94887039239 77.14716223003516 66.86088856518572 0.9700115340253749\n",
      "7 73.00357568533968 77.20181177654756 66.91015339663988 0.9677047289504037\n",
      "8 73.14593301435407 77.33467945482082 67.05796038151138 0.9642445213379469\n",
      "9 73.22929171668667 77.42914979757084 67.10914454277285 0.9607843137254902\n",
      "10 73.32931968693558 77.52409944190765 67.20947446336046 0.9579008073817762\n",
      "11 73.35744424352019 77.54065040650406 67.25925925925925 0.9567474048442907\n",
      "12 73.4422262552934 77.63627101375447 67.31198808637379 0.9532871972318339\n",
      "13 73.60097323600974 77.78915046059366 67.46626686656673 0.9480968858131488\n",
      "14 73.63914373088684 77.88609543355567 67.37320211960636 0.9429065743944637\n",
      "15 73.63245236631838 77.89799072642967 67.32673267326732 0.9382929642445214\n",
      "16 73.70689655172414 77.95560144553431 67.42944317315026 0.936562860438293\n",
      "17 73.71992597162246 77.97311271975181 67.43119266055047 0.9348327566320646\n",
      "18 73.63861386138613 77.90456431535272 67.33128834355828 0.9319492502883506\n",
      "19 73.75930521091811 78.00312012480498 67.48654880860876 0.9296424452133795\n",
      "20 73.80211574362166 78.01566579634465 67.59045419553503 0.9267589388696655\n",
      "21 73.95377888819488 78.17896389324962 67.69945778466304 0.9232987312572087\n",
      "22 74.01129943502825 78.2791185729276 67.65625 0.9186851211072664\n",
      "23 74.06940063091483 78.35703001579779 67.66325727773408 0.9140715109573241\n",
      "24 74.24050632911393 78.52242744063325 67.82608695652173 0.9111880046136102\n",
      "25 74.26937738246505 78.56008470089994 67.83161239078633 0.9077277970011534\n",
      "26 74.4408945686901 78.74601487778958 67.94871794871794 0.9025374855824683\n",
      "27 74.4721689059501 78.78787878787877 67.95180722891565 0.9013840830449827\n",
      "28 74.53376205787781 78.84615384615384 68.0129240710824 0.8967704728950404\n",
      "29 74.56423499031634 78.90792291220556 67.96747967479675 0.8933102652825836\n",
      "30 74.6268656716418 78.98979043524986 67.97706797706797 0.8886966551326413\n",
      "31 74.67447916666667 79.02964959568733 68.03615447822514 0.8858131487889274\n",
      "32 74.83617300131061 79.17570498915401 68.21192052980133 0.8800461361014994\n",
      "33 74.93438320209974 79.26167209554832 68.32504145936983 0.8788927335640139\n",
      "34 75.18151815181518 79.4535519125683 68.66666666666667 0.8737024221453287\n",
      "35 75.26525198938992 79.51674903898956 68.7866108786611 0.8696655132641292\n",
      "36 75.34976682211858 79.58057395143487 68.90756302521008 0.8656286043829297\n",
      "37 75.53619302949062 79.73348139922264 69.1462383770076 0.8604382929642446\n",
      "38 75.60810810810811 79.86614612381483 69.06598114824337 0.8535178777393311\n",
      "39 75.74728260869566 80.0447177193963 69.0909090909091 0.8489042675893888\n",
      "40 75.86912065439672 80.15695067264573 69.21739130434781 0.8460207612456747\n",
      "41 75.82191780821918 80.11267605633805 69.1703056768559 0.8419838523644751\n",
      "42 75.92847317744155 80.22598870056498 69.24428822495607 0.8385236447520185\n",
      "43 75.86445366528353 80.15918135304149 69.19682259488084 0.8339100346020761\n",
      "44 75.88357588357589 80.20477815699658 69.14893617021278 0.8321799307958477\n",
      "45 75.90529247910864 80.22857142857143 69.16221033868092 0.8281430219146482\n",
      "46 75.96086652690427 80.25258323765786 69.28571428571429 0.8252595155709342\n",
      "47 76.05337078651685 80.32313906520484 69.4170403587444 0.8212226066897347\n",
      "48 76.12676056338029 80.4159445407279 69.43192064923353 0.8189158016147635\n",
      "49 76.20056497175142 80.48639258830342 69.50226244343891 0.8166089965397924\n",
      "50 76.34943181818181 80.60570762958649 69.69972702456778 0.81199538638985\n",
      "51 76.26876340243031 80.58479532163743 69.48529411764706 0.8068050749711649\n",
      "52 76.34408602150538 80.65650644783119 69.55719557195572 0.8044982698961938\n",
      "53 76.3271162123386 80.65650644783119 69.50092421441775 0.803921568627451\n",
      "54 76.40287769784173 80.70588235294117 69.62962962962962 0.8016147635524798\n",
      "55 76.61115133960898 80.89887640449439 69.84126984126983 0.7964244521337946\n",
      "56 76.62053896576839 80.92691622103386 69.80244590780809 0.7918108419838523\n",
      "57 76.66422823701537 80.95522388059702 69.87724268177526 0.7883506343713956\n",
      "58 76.84365781710915 81.10709987966305 70.09523809523809 0.7820069204152249\n",
      "59 76.9059955588453 81.20481927710843 70.05758157389634 0.779123414071511\n",
      "60 77.16417910447761 81.45454545454545 70.29126213592232 0.7727797001153403\n",
      "61 77.4024024024024 81.65752589884217 70.57673509286413 0.7681660899653979\n",
      "62 77.56797583081571 81.79031269160025 70.79646017699115 0.7635524798154556\n",
      "63 77.66768292682927 81.8800247371676 70.90367428003972 0.7566320645905421\n",
      "64 77.83742331288343 82.01617921593031 71.12887112887113 0.7520184544405998\n",
      "65 78.20710973724884 82.30865746549561 71.6297786720322 0.7462514417531718\n",
      "66 78.22706065318818 82.34552332912989 71.60243407707911 0.7416378316032295\n",
      "67 78.1789638932496 82.38276299112802 71.34020618556701 0.734717416378316\n",
      "68 78.38479809976248 82.55591054313099 71.59209157127994 0.7283737024221453\n",
      "69 78.62289831865492 82.74078862314157 71.92429022082018 0.7202998846597463\n",
      "70 78.76106194690266 82.83485045513655 72.15189873417724 0.7168396770472895\n",
      "71 79.04142973192526 83.1151832460733 72.37687366167023 0.709919261822376\n",
      "72 79.19737919737919 83.22324966974901 72.62931034482759 0.7041522491349481\n",
      "73 79.47019867549669 83.51063829787233 72.80701754385966 0.6966551326412919\n",
      "74 79.68227424749163 83.68032236400269 73.08970099667775 0.6897347174163783\n",
      "75 79.69671440606571 83.70520622041921 73.07262569832403 0.6845444059976932\n",
      "76 79.76190476190476 83.78746594005449 73.07692307692307 0.6782006920415224\n",
      "77 80.03442340791739 84.1095890410959 73.14814814814815 0.6701268742791234\n",
      "78 80.29513888888889 84.31237042156185 73.512252042007 0.6643598615916955\n",
      "79 80.72183098591549 84.63157894736841 74.14403778040142 0.6551326412918108\n",
      "80 80.62222222222222 84.56090651558074 73.98568019093078 0.6487889273356401\n",
      "81 80.91397849462365 84.796573875803 74.3682310469314 0.643598615916955\n",
      "82 81.19891008174388 85.03253796095446 74.72527472527473 0.6349480968858131\n",
      "83 81.3247470101196 85.23636363636363 74.59324155193993 0.6268742791234141\n",
      "84 81.36067101584342 85.27245949926363 74.61928934010153 0.618800461361015\n",
      "85 81.33333333333333 85.17397881996975 74.80719794344473 0.6055363321799307\n",
      "86 81.78294573643412 85.53846153846153 75.39267015706807 0.5951557093425606\n",
      "87 81.88118811881188 85.64705882352942 75.43624161073825 0.5824682814302191\n",
      "88 82.09562563580874 85.87479935794543 75.55555555555554 0.5668973471741637\n",
      "89 82.1875 85.99508599508599 75.53648068669527 0.5536332179930796\n",
      "90 82.42811501597444 86.28428927680797 75.55555555555556 0.5415224913494809\n",
      "91 82.560706401766 86.37931034482757 75.76687116564416 0.5224913494809689\n",
      "92 82.80182232346242 86.60159716060336 75.99364069952306 0.5063437139561707\n",
      "93 83.31346841477949 87.03703703703705 76.5886287625418 0.48385236447520186\n",
      "94 83.76703841387857 87.46411483253588 76.97715289982425 0.46539792387543255\n",
      "95 84.15584415584415 87.8243512974052 77.32342007434944 0.44405997693194926\n",
      "96 84.78561549100968 88.27292110874201 78.34645669291338 0.41695501730103807\n",
      "97 84.95575221238938 88.56502242152466 78.01724137931035 0.39100346020761245\n",
      "98 84.89326765188834 88.72549019607843 77.11442786069652 0.35121107266435986\n",
      "99 86.17234468937876 89.95633187772926 77.81350482315112 0.2877739331026528\n"
     ]
    }
   ],
   "source": [
    "# testing the self-awareness of ml_model\n",
    "# result: positive correlation between ml_model confidence score and its evaluation metrics\n",
    "\n",
    "for confidence in range(100):\n",
    "    true_pos, true_neg, false_pos, false_neg, indecision = eval_model(ml_model, test_data, confidence)\n",
    "    total_decisions = false_pos + false_neg + true_pos + true_neg\n",
    "    accuracy = 100 * (true_pos + true_neg) / total_decisions\n",
    "    pos_precision = 100 * true_pos / (true_pos + false_pos)\n",
    "    pos_recall = 100 * true_pos / (true_pos + false_neg)\n",
    "    pos_f1 = 2 * pos_precision * pos_recall / (pos_recall + pos_precision)\n",
    "    neg_precision = 100 * true_neg / (true_neg + false_neg)\n",
    "    neg_recall = 100 * true_neg / (true_neg + false_pos)\n",
    "    neg_f1 = 2 * neg_precision * neg_recall / (neg_recall + neg_precision)\n",
    "    reliability = total_decisions / (total_decisions + indecision)\n",
    "\n",
    "    print(confidence, accuracy, pos_f1, neg_f1, reliability)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
